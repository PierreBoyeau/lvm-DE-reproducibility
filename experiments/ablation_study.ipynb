{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING OFFSET = 1e-10\n",
      "[]\n",
      "1 2 (2000,) (2000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/conda/envs/DE/lib/python3.7/site-packages/pandas/core/computation/expressions.py:205: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "INFO:scvi.dataset.dataset:Remapping batch_indices to [0,N]\n",
      "INFO:scvi.dataset.dataset:Remapping labels to [0,N]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data distrib:  pop\n",
      "1    2000\n",
      "2    2000\n",
      "3    2000\n",
      "4    2000\n",
      "5    2000\n",
      "Name: pop, dtype: int64\n",
      "pop\n",
      "1    2000\n",
      "2     500\n",
      "3     100\n",
      "4    2000\n",
      "5    2000\n",
      "Name: pop, dtype: int64\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from scvi.dataset import GeneExpressionDataset\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.models import VAE\n",
    "from scvi.utils import make_dir_if_necessary\n",
    "\n",
    "\n",
    "N_CELLS_QUERY = 100\n",
    "FOLDER_NAME = \"runs/symsim_ablation_study\"\n",
    "DELTA = 0.8\n",
    "SEED = 0\n",
    "N_CELLS_REF = 500\n",
    "N_OTHERS = 2000\n",
    "OFFSET = 1e-10\n",
    "\n",
    "N_EPOCHS = 1000\n",
    "N_PICKS = 1\n",
    "N_SAMPLES = 10000\n",
    "\n",
    "print(\"USING OFFSET = {}\".format(OFFSET))\n",
    "\n",
    "RECONSTRUCTION_LOSS = \"nb\"\n",
    "N_PICKS = 2\n",
    "ADVANCED_PROPS = True\n",
    "N_SAMPLES = 5000\n",
    "# N_EPOCHS = 500\n",
    "N_LATENT = 50\n",
    "PIN_MEMORY = False\n",
    "USE_BATCH_NORM = False\n",
    "PATH_TO_SCRIPTS = \"MYPATHTOSCRIPTS\"\n",
    "DIR_PATH = \"{FOLDER_NAME}/symsim_bimod_{N_CELLS_QUERY}_{N_CELLS_REF}_{OFFSET}_{DELTA}_{N_OTHERS}_{SEED}\".format(\n",
    "    FOLDER_NAME=FOLDER_NAME,\n",
    "    N_CELLS_QUERY=N_CELLS_QUERY,\n",
    "    N_CELLS_REF=N_CELLS_REF,\n",
    "    OFFSET=OFFSET,\n",
    "    DELTA=DELTA,\n",
    "    N_OTHERS=N_OTHERS,\n",
    "    SEED=SEED,\n",
    ")\n",
    "\n",
    "\n",
    "Q0 = 1e-1\n",
    "# np.random.seed(SEED)\n",
    "make_dir_if_necessary(DIR_PATH)\n",
    "print(os.listdir(DIR_PATH))\n",
    "\n",
    "#####################################################\n",
    "#####################################################\n",
    "symsim_data_path = (\n",
    "    \"./data/symsim_nevf30.n_de_evf_18.sigma_0.rep_1/DE\"\n",
    ")\n",
    "x_obs_all = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"DE_med.obsv.3.csv\"), index_col=0\n",
    ").T\n",
    "batch_info = (\n",
    "    pd.read_csv(os.path.join(symsim_data_path, \"DE_med.batchid.csv\"), index_col=0) - 1\n",
    ")\n",
    "metadata = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"DE_med.cell_meta.csv\"), index_col=0\n",
    ")\n",
    "\n",
    "x_obs = x_obs_all\n",
    "\n",
    "# NEW\n",
    "label_a = 1\n",
    "label_b = 2\n",
    "\n",
    "k_on = pd.read_csv(os.path.join(symsim_data_path, \"DE_med.kon_mat.csv\"))\n",
    "k_off = pd.read_csv(os.path.join(symsim_data_path, \"DE_med.koff_mat.csv\"))\n",
    "s_mat = pd.read_csv(os.path.join(symsim_data_path, \"DE_med.s_mat.csv\"))\n",
    "\n",
    "k_on = k_on.values.T\n",
    "k_off = k_off.values.T\n",
    "s_mat = s_mat.values.T\n",
    "\n",
    "# labels = dataset.labels.squeeze()\n",
    "labels = metadata[\"pop\"].values - 1\n",
    "where_a = np.where(labels == 1)[0]  # [:1000]\n",
    "where_b = np.where(labels == 2)[0]  # [:1000]\n",
    "print(label_a, label_b, where_a.shape, where_b.shape)\n",
    "means_a = s_mat[where_a] * k_on[where_a] / (k_on[where_a] + k_off[where_a])\n",
    "means_b = s_mat[where_b] * k_on[where_b] / (k_on[where_b] + k_off[where_b])\n",
    "lfc_dist_gt = (np.log2(means_a) - np.log2(means_b))[:, select_gene]\n",
    "lfc_gt = lfc_dist_gt.mean(0)\n",
    "lfc_gt_alt = np.log2(means_a.mean(0)) - np.log2(means_b.mean(0))\n",
    "\n",
    "\n",
    "select_gene = np.arange(x_obs_all.values.shape[1])\n",
    "non_null_genes = x_obs_all.sum(0) > 0\n",
    "bimod_select = (np.abs(lfc_gt) <= 0.2) | (np.abs(lfc_gt) >= 1.0)\n",
    "\n",
    "select_gene = non_null_genes * bimod_select\n",
    "# x_obs_all = x_obs_all.loc[:, non_null_genes]\n",
    "\n",
    "x_obs = x_obs_all.loc[:, select_gene]\n",
    "true_ = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"DE_med.true.csv\"), index_col=0\n",
    ").T.loc[:, select_gene]\n",
    "lfc_info = pd.read_csv(\n",
    "    os.path.join(symsim_data_path, \"med_theoreticalFC.csv\"), index_col=0\n",
    ").loc[select_gene, :]\n",
    "# lfc_info[d_key].values\n",
    "print(\"Original data distrib: \", metadata[\"pop\"].groupby(metadata[\"pop\"]).size())\n",
    "\n",
    "# Data only\n",
    "# n_examples_ct = np.array([2000, 2000, 2000, 2000, 2000])\n",
    "n_examples_ct = np.array([N_OTHERS, N_CELLS_REF, N_CELLS_QUERY, N_OTHERS, N_OTHERS])\n",
    "\n",
    "selected_indices = (\n",
    "    metadata[\"pop\"]\n",
    "    .sample(frac=1.0, random_state=SEED)\n",
    "    .groupby(metadata[\"pop\"])\n",
    "    .apply(lambda x: x.iloc[: n_examples_ct[x.name - 1]].index.values)\n",
    ")\n",
    "# selected_indices = np.ar\n",
    "indices = np.concatenate(selected_indices.values) - 1\n",
    "print(selected_indices.apply(lambda x: len(x)))\n",
    "\n",
    "dataset = GeneExpressionDataset()\n",
    "dataset.populate_from_data(\n",
    "    X=x_obs.values[indices],\n",
    "    batch_indices=batch_info[\"x\"].values[indices],\n",
    "    labels=metadata[\"pop\"].values[indices],\n",
    "    cell_types=metadata[\"pop\"].values[indices],\n",
    ")\n",
    "\n",
    "\n",
    "label_a = 1\n",
    "label_b = 2\n",
    "n_genes = dataset.nb_genes\n",
    "\n",
    "d_key = \"{}{}\".format(label_a + 1, label_b + 1)\n",
    "print(d_key)\n",
    "\n",
    "is_significant_de = (lfc_info[d_key].abs() >= DELTA).values\n",
    "lfc_gt = lfc_info[d_key].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = dataset.labels.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,) (100,)\n"
     ]
    }
   ],
   "source": [
    "idx_a = np.where(y_all == 1)[0]\n",
    "idx_b = np.where(y_all == 2)[0]\n",
    "print(idx_a.shape, idx_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "\n",
    "from experiments_utils import get_eb_full\n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scVI-lvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6cac957e50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_iw_kwargs = dict(\n",
    "    n_latent=10,\n",
    "    dropout_rate=0.0,\n",
    "    decoder_dropout_rate=0.0,\n",
    "    reconstruction_loss=\"nb\",\n",
    "    dispersion=\"gene\",\n",
    "    n_layers=1,\n",
    "    use_batch_norm=False,\n",
    "    use_weight_norm=False,\n",
    "    use_layer_norm=True,\n",
    "    with_activation=nn.ReLU(),\n",
    ")\n",
    "trainer_iw_kwargs = dict(\n",
    "    train_library=True,\n",
    "    batch_size=1024,\n",
    "    weight_decay=1e-4,\n",
    "    k=25,\n",
    "    loss_type=\"IWELBO\",\n",
    "    optimizer_type=\"adam\",\n",
    "    test_indices=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = None\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "N_EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + ELBO\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 500/500 [07:39<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1eb41d893c443ad8955b21e1646ae7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3061.9269976151363\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1a9220c4c845d496e1a09244b6c200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 5227.2292595625095\n",
      "INFO:root:LFC MEAN in batch 0: -0.11193183064460754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.055305612884695e-05\n",
      "using offset: 2.055305612884695e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f7b165145c41adb6c01c00ce380758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3711.079099293939\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8f1af10fbd4f55bcc385f1cb3d30e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 4055.3752210202224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: -0.06949496269226074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.8460470164427535e-05\n",
      "using offset: 1.8460470164427535e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.60426432514688\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + IWELBO\n",
      "\n",
      "training: 100%|██████████| 500/500 [07:54<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34958e9f16c44807b36038c6dbe87a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 6196.806810912451\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5229fdf29bc4cff8823fccc97fce804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 2722.2530006412712\n",
      "INFO:root:LFC MEAN in batch 0: -0.03231319412589073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.6650638210412582e-05\n",
      "using offset: 2.6650638210412582e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0614022cb34533a08a53434db6027b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2480.264986714673\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21bf5a0d4484e348aa5d1739fb1a406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2815.2648137232586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: 0.032972726970911026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 4.0338560756936205e-05\n",
      "using offset: 4.0338560756936205e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.6104008034329017\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + ELBO\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [07:46<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9bce71d15f4cfd910074400e5da817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 489.6740463026535\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751fa7947d89447181587577baaf0462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 2455.379137650846\n",
      "INFO:root:LFC MEAN in batch 0: -0.01392677053809166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.9299084962985945e-05\n",
      "using offset: 2.9299084962985945e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab5145cf2b44258afb5dbdca5f481f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 47.565299247481335\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f20a43cd4d46eb8c168aa0349224e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2819.2473986378072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: 0.006663477048277855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.468234615662368e-05\n",
      "using offset: 2.468234615662368e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.6576961645592457\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + IWELBO\n",
      "\n",
      "training: 100%|██████████| 500/500 [07:40<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b8db19d3b54575874881abb709defa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1742.710932672924\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7fc0b7b43149b5b28293b32d38f573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 3863.3660460384963\n",
      "INFO:root:LFC MEAN in batch 0: -0.18288566172122955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.253248087276006e-05\n",
      "using offset: 3.253248087276006e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2f27ad915948e28b695638b7737d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 251.7258028121532\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2be5417f97c4f31825e581bbdc88c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2956.0085088268843\n",
      "INFO:root:LFC MEAN in batch 1: -0.04444705322384834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.979651191912126e-05\n",
      "using offset: 3.979651191912126e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.6686945641133498\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + ELBO\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [08:53<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf93113649349ecbe2be38f61a83560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 5058.18255113941\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c12c3ce21d40f6947d20b24d3de8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 7387.945423395281\n",
      "INFO:root:LFC MEAN in batch 0: -0.059859324246644974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.382230415809318e-05\n",
      "using offset: 3.382230415809318e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679c540ae916467394e9da7693c57ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 4536.730515825302\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e111de5e86a54063a0ed87e9003f9ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 5122.227913000473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: 0.025147899985313416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.0444904859905366e-05\n",
      "using offset: 3.0444904859905366e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.5872585724164293\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + IWELBO\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:08<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cec544bb3747c99c56ed65abc0fbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3762.5615451236513\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b79a2a89e44e2fb3351377c46a9ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2487.7901766148984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: -0.19055548310279846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 5.148357049620245e-05\n",
      "using offset: 5.148357049620245e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14eafd818b24cfcb39f3b03285216dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1565.3730631322132\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a005e7bbe2c4dd9960b3aa9f8b2ab52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3338.030351631533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: -0.11163237690925598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.347860438225325e-05\n",
      "using offset: 3.347860438225325e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.6144859129049859\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + ELBO\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [08:57<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f056ae0128234987a56e4dea4039a0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3634.6842029878685\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a8252516484fcaa36845aa214e6730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 4659.844792895717\n",
      "INFO:root:LFC MEAN in batch 0: -0.12352462112903595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.616145475258236e-05\n",
      "using offset: 2.616145475258236e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460f2f547eda4bf69e987f05eafa46ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 395.02648178366803\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386244e29ecf4b02a5bec77b3680cec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3848.196062378434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: -0.06594417989253998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.1291569484892534e-05\n",
      "using offset: 3.1291569484892534e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.524262125130259\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + IWELBO\n",
      "\n",
      "training: 100%|██████████| 500/500 [08:57<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d212e16451443daa0a3686ee0c7538a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 4084.4316906288086\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7141a9401445859cab35b41a2f9dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 2456.7137376888995\n",
      "INFO:root:LFC MEAN in batch 0: 0.05967044085264206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.794392462419637e-05\n",
      "using offset: 2.794392462419637e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa3109929044b3496e7587fa6e9aaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3266.469545833689\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b673c281cf94828a59a478ffa428af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 2068.733181962243\n",
      "INFO:root:LFC MEAN in batch 1: 0.12447533011436462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.4135495550581257e-05\n",
      "using offset: 2.4135495550581257e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.6457758267331456\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + ELBO\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [08:46<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefe98a21f30425e9ac6245266cd2332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 4549.764938232763\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5099f7cc0e3f4baeb602ec9a69ddecb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2185.8791619494323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: -0.1980847418308258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 5.3778501933265946e-05\n",
      "using offset: 5.3778501933265946e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548e2359e5094b448f8b361d3331879e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1375.7377577225682\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecaaa9d169cb4f2aa264f9eb0d015d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2371.162849474869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: -0.1521080732345581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 4.096273241884774e-05\n",
      "using offset: 4.096273241884774e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.5675936240793173\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI-lvm + IWELBO\n",
      "\n",
      "training: 100%|██████████| 500/500 [08:45<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:... done!\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc7c6cf696f435f85fe7c2c6592d413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1617.7178539217903\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09189334d01a42d080f962fae217e750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1913.8098567528036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: -0.15114112198352814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.663988570930087e-05\n",
      "using offset: 2.663988570930087e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fd823f08df4a1aa2a80b55b18cadf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 945.9460498302625\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd99f34b5cf24feebdb8b7b35f9bea93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2223.491624665802\n",
      "INFO:root:LFC MEAN in batch 1: -0.07170718163251877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.7267740006209354e-05\n",
      "using offset: 2.7267740006209354e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.6499730533375946\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "algos = [\n",
    "    dict(\n",
    "        name=\"scVI-lvm + ELBO\", \n",
    "        trainer_kwargs=dict(loss_type=\"ELBO\", k=1)\n",
    "    ),\n",
    "#     dict(\n",
    "#         name=\"scVI-lvm + ELBO + LN + NOWD\", \n",
    "#         trainer_kwargs=dict(loss_type=\"ELBO\", k=1, weight_decay=0.)\n",
    "#     ),\n",
    "#     dict(\n",
    "#         name=\"scVI-lvm + ELBO + BN\", \n",
    "#         trainer_kwargs=dict(loss_type=\"ELBO\", k=1),\n",
    "#         mdl_kwargs=dict(use_batch_norm=True, use_layer_norm=False)\n",
    "#     ),\n",
    "#     dict(name=\"scVI-lvm (fixed LR)\", autolr=False),\n",
    "#     dict(name=\"scVI-lvm + BN\", mdl_kwargs=dict(use_batch_norm=True, use_layer_norm=False)),\n",
    "    dict(name=\"scVI-lvm + IWELBO\"),\n",
    "#     dict(name=\"scVI-lvm + IWELBO\", trainer_kwargs=dict(weight_decay=0.)),\n",
    "#     dict(name=\"scVI-lvm + DREG + LN\", trainer_kwargs=dict(loss_type=\"IWELBO\")),\n",
    "#     dict(name=\"scVI-lvm + DREG + LN + NOWD\", trainer_kwargs=dict(loss_type=\"IWELBO\", weight_decay=0.)),\n",
    "#     dict(name=\"scVI-lvm + BN + NOWD\", mdl_kwargs=dict(use_batch_norm=True, use_layer_norm=False), trainer_kwargs=dict(weight_decay=0.)),\n",
    "#     dict(name=\"scVI-lvm + IWELBO ++ LN2 + NOWD\", mdl_kwargs=dict(use_batch_norm=False, use_layer_normb=True, use_layer_norm=False), trainer_kwargs=dict(weight_decay=0.)),\n",
    "#     dict(name=\"scVI-lvm + LN2\", mdl_kwargs=dict(use_batch_norm=False, use_layer_normb=True, use_layer_norm=False)),\n",
    "]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for iterate in range(5):\n",
    "    for algo in (algos):\n",
    "        # Overall parameters\n",
    "        algo = algo.copy()\n",
    "        algo_name = algo.pop(\"name\")\n",
    "        autolr = algo.pop(\"autolr\", True)\n",
    "        print(algo_name)\n",
    "\n",
    "        # Model parameters\n",
    "        mdl_params_iter = mdl_iw_kwargs.copy()\n",
    "        _mdl_params_iter = algo.pop(\"mdl_kwargs\", dict())\n",
    "        for key, new_val in _mdl_params_iter.items():\n",
    "            print(key, new_val)\n",
    "            mdl_params_iter[key] = new_val\n",
    "\n",
    "        # Trainer parameters\n",
    "        trainer_params_iter = trainer_iw_kwargs.copy()\n",
    "        _trainer_params_iter = algo.pop(\"trainer_kwargs\", dict())\n",
    "        for key, new_val in _trainer_params_iter.items():\n",
    "            print(key, new_val)\n",
    "            trainer_params_iter[key] = new_val\n",
    "\n",
    "        print()\n",
    "\n",
    "        mdl_iw = VAE(n_input=dataset.nb_genes, n_batch=dataset.n_batches, **mdl_params_iter)\n",
    "        trainer_iw = UnsupervisedTrainer(\n",
    "            model=mdl_iw, gene_dataset=dataset, **trainer_params_iter\n",
    "        )\n",
    "#         if not autolr:\n",
    "        logging.info(\"Using fixed LR\")\n",
    "        lr_iw = 1e-3\n",
    "#         else:\n",
    "#             lr_iw = trainer_iw.find_lr()\n",
    "#             mdl_iw = VAE(n_input=dataset.nb_genes, n_batch=dataset.n_batches, **mdl_params_iter)\n",
    "#             trainer_iw = UnsupervisedTrainer(\n",
    "#                 model=mdl_iw, gene_dataset=dataset, **trainer_params_iter\n",
    "#             )\n",
    "    \n",
    "        logging.info(\"Using learning rate {}\".format(lr_iw))\n",
    "        trainer_iw.train(n_epochs=N_EPOCHS, lr=lr_iw)\n",
    "        mdl_iw.eval()\n",
    "        \n",
    "        lls = trainer_iw.train_set.marginal_llb(custom_batch_index=None).mean().item()\n",
    "\n",
    "        mf_props_eb = get_eb_full(\n",
    "            trainer=trainer_iw,\n",
    "            idx_a=idx_a,\n",
    "            mode_coeff=0.6,\n",
    "            idx_b=idx_b,\n",
    "            offset=None,\n",
    "            delta=None,\n",
    "            # n_samples=30000,\n",
    "            n_samples=50000,\n",
    "            include_lib=False,\n",
    "            # keeping_k_best_subsamples=20000,\n",
    "            do_batch_specific=\"separation\",\n",
    "            posterior_chunks=200,\n",
    "            do_normalize=True,\n",
    "            filter_cts=True,\n",
    "#             coef_truncate=.5,\n",
    "        )\n",
    "        \n",
    "        subres_d = {**mf_props_eb, **dict(lfc_gt=lfc_gt, is_significant_de=is_significant_de)}\n",
    "        subres = pd.DataFrame(subres_d).assign(algo_name=algo_name, iterate=iterate, iwelbo5000=lls)\n",
    "        results = results.append(subres, ignore_index=True)\n",
    "    #     break\n",
    "\n",
    "results.to_pickle(\"lfc_estimates_both_rareFIXED5/symsim_ablation_study/results_iw7.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scPhere-lvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm', 'mdl_kwargs': {'deep_architecture': True}}\n",
      "scPhere-lvm\n",
      "deep_architecture True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:26<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17220c41905c4c37a7ba8d1c5f92b185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 4124.714547172281\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb8ee64bf6c4c45bc938c4af0f558a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3108.2473818289354\n",
      "INFO:root:LFC MEAN in batch 0: -0.0951203778386116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.9073276553172037e-05\n",
      "using offset: 1.9073276553172037e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724a785ede9f45929547daad54d05952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 5969.58310379683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1d188adb4a4b2ab1b6755104a4f760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 2159.5305893929285\n",
      "INFO:root:LFC MEAN in batch 1: -0.06774439662694931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.0410329125297724e-05\n",
      "using offset: 2.0410329125297724e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.6869967148387407\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - constant overdispersion', 'mdl_kwargs': {'deep_architecture': True, 'constant_pxr': False, 'cell_specific_px': True}}\n",
      "scPhere-lvm - constant overdispersion\n",
      "deep_architecture True\n",
      "constant_pxr False\n",
      "cell_specific_px True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:27<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4c1eed58474730934e65a607b3efe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3651.948229094536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad24490095647a99c7d7be60e819873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1300.257880186606\n",
      "INFO:root:LFC MEAN in batch 0: -0.2754214406013489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.305536279687658e-05\n",
      "using offset: 1.305536279687658e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972db4f36a8d414aa1bfd276e659a227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 3392.6788442646853\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7fafc375614875ad1ed330b47cceae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1080.049719379823\n",
      "INFO:root:LFC MEAN in batch 1: -0.28604429960250854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.4736908360646339e-05\n",
      "using offset: 1.4736908360646339e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.7117565103665078\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm + ELBO', 'mdl_kwargs': {'deep_architecture': True}, 'trainer_kwargs': {'loss_type': 'ELBO', 'k': 1}}\n",
      "scPhere-lvm + ELBO\n",
      "deep_architecture True\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:16<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ab045e6428450f8dacd41d23c7098c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24601.90814310744\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b229249dafd4fbc84078f479ee7a3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 24642.79039985312\n",
      "INFO:root:LFC MEAN in batch 0: -0.00016765388136263937\n",
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.0248144230426992e-05\n",
      "using offset: 3.0248144230426992e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4e536f17e64fbe9a3e404756bf2308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24337.186184787657\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf91911cd734ab49fcf3433a6831484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24529.40248426342\n",
      "INFO:root:LFC MEAN in batch 1: 0.00020858734205830842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.154167957291065e-05\n",
      "using offset: 3.154167957291065e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 2.3093607143632818e-05\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - library size', 'mdl_kwargs': {'deep_architecture': True, 'full': False}}\n",
      "scPhere-lvm - library size\n",
      "deep_architecture True\n",
      "full False\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:11<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd799d5c53824a7d82739f28897787e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 4271.407812285363\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e86531d0dc144b6bbecba19bde7ed51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2002.477260869991\n",
      "INFO:root:LFC MEAN in batch 0: -0.2341708093881607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.0006328079725791e-05\n",
      "using offset: 1.0006328079725791e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f94e0a6b19403b9180e900c00e493a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3138.8410945028572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ac780e37964c4b8d7d1de417b17f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 683.9675349431244\n",
      "INFO:root:LFC MEAN in batch 1: -0.13005976378917694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.0242587126849688e-05\n",
      "using offset: 3.0242587126849688e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.2792427404007011\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm', 'mdl_kwargs': {'deep_architecture': True}}\n",
      "scPhere-lvm\n",
      "deep_architecture True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:30<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ecb72c5ace4977a39efe99d85d8aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 4366.344197492929\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999407ef97304392819464616093ca25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1669.5348467519575\n",
      "INFO:root:LFC MEAN in batch 0: 0.14418083429336548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.2122495920484653e-05\n",
      "using offset: 2.2122495920484653e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b0cfca6112465bb315cb5e8800b72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 5674.141976502334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357d4ee9549049629f13f4d03a2037b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1593.6123286795728\n",
      "INFO:root:LFC MEAN in batch 1: 0.11257922649383545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.1516033712032367e-05\n",
      "using offset: 2.1516033712032367e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.7214840730184392\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - constant overdispersion', 'mdl_kwargs': {'deep_architecture': True, 'constant_pxr': False, 'cell_specific_px': True}}\n",
      "scPhere-lvm - constant overdispersion\n",
      "deep_architecture True\n",
      "constant_pxr False\n",
      "cell_specific_px True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:30<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a08e62181045c5a40b0565e7744798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2630.675825306176\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4fa4cefa9a4dc38562624fecfd8bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1299.973144075577\n",
      "INFO:root:LFC MEAN in batch 0: -0.28780806064605713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.4493775415758136e-05\n",
      "using offset: 1.4493775415758136e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76b524b2bd9441b8215ba018fd8769e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1957.0379269547689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cebbd42f064e068bf6b5fc1158bf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1445.8789975218724\n",
      "INFO:root:LFC MEAN in batch 1: -0.3293267786502838\n",
      "INFO:root:DELTA VALUE: 0.70285444969763\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.4473613009613474e-05\n",
      "using offset: 1.4473613009613474e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm + ELBO', 'mdl_kwargs': {'deep_architecture': True}, 'trainer_kwargs': {'loss_type': 'ELBO', 'k': 1}}\n",
      "scPhere-lvm + ELBO\n",
      "deep_architecture True\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:24<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6b9c5f1df54208b4edc6f075e92693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24715.782249854652\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7929dc6cb74e1b9a85118f288e6064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24823.508365083908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: -6.375775410560891e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.843931465577043e-05\n",
      "using offset: 2.843931465577043e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8493fa95a8694509b59a4c57d009d7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24556.277071384375\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ea000eb5ba4f288f160b1b4b2766cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24720.679016608072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: 0.00010056315659312531\n",
      "INFO:root:DELTA VALUE: 1.0947095288949749e-05\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.1797497604202364e-05\n",
      "using offset: 3.1797497604202364e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - library size', 'mdl_kwargs': {'deep_architecture': True, 'full': False}}\n",
      "scPhere-lvm - library size\n",
      "deep_architecture True\n",
      "full False\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:20<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a5d5a0c1da4d56b0e57039138113e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3868.361925166442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0069a12d1dd4b19b33f1976217b2865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2886.9125216835164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: -0.04133881255984306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 8.936106632972951e-06\n",
      "using offset: 8.936106632972951e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b98659258c14e3dba6396f19e874c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 4505.1762874088345\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a844d8deffa64a288ffa032b53622190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 2196.450912815769\n",
      "INFO:root:LFC MEAN in batch 1: -0.04719632863998413\n",
      "INFO:root:DELTA VALUE: 0.38988676991436466\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.8921245075252955e-05\n",
      "using offset: 2.8921245075252955e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm', 'mdl_kwargs': {'deep_architecture': True}}\n",
      "scPhere-lvm\n",
      "deep_architecture True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:33<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab390cbe97b4526b7f719145dd49e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 3596.745482470024\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6a93f6c89f48478255bf0a43833509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1808.39129254015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: 0.06500477343797684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.3949009985481099e-05\n",
      "using offset: 1.3949009985481099e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b57ab421b8423dacaf84aeb002b52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 5588.794084551486\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a8aa6b03f74b52a2e5d46970eedf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1817.4716834062938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: 0.08405730128288269\n",
      "INFO:root:DELTA VALUE: 0.7180403877386439\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.4241501799006074e-05\n",
      "using offset: 1.4241501799006074e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - constant overdispersion', 'mdl_kwargs': {'deep_architecture': True, 'constant_pxr': False, 'cell_specific_px': True}}\n",
      "scPhere-lvm - constant overdispersion\n",
      "deep_architecture True\n",
      "constant_pxr False\n",
      "cell_specific_px True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:41<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6036b96981a14d318bf148550c3fa6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2923.2468610589585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aeccb2ffc2d486ca293bbb5679975e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 519.6839881058614\n",
      "INFO:root:LFC MEAN in batch 0: -0.27680590748786926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.448215284151957e-05\n",
      "using offset: 3.448215284151957e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0567683474204e078fbdb93e5335d9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3443.452326562829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0861bcc3e84389a1a8ddbaf9e8b8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1061.2335286870348\n",
      "INFO:root:LFC MEAN in batch 1: -0.2865023910999298\n",
      "INFO:root:DELTA VALUE: 0.715534107447826\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.6724391045718224e-05\n",
      "using offset: 2.6724391045718224e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm + ELBO', 'mdl_kwargs': {'deep_architecture': True}, 'trainer_kwargs': {'loss_type': 'ELBO', 'k': 1}}\n",
      "scPhere-lvm + ELBO\n",
      "deep_architecture True\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:31<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d599595d87024522a48bd91fb59f760f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24623.466010704768\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e69ae674b244148d09e976de11ba6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 23587.016997403418\n",
      "INFO:root:LFC MEAN in batch 0: 0.00010568129800958559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.055276833947574e-05\n",
      "using offset: 3.055276833947574e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc45573f53e1408ababfe279d945fe0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24239.546082119494\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb96c6e14c1141faa00ac6544ddf0ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 22959.70327097242\n",
      "INFO:root:LFC MEAN in batch 1: 0.0003562182537280023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.121252525488671e-05\n",
      "using offset: 3.121252525488671e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.00014016351481301286\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - library size', 'mdl_kwargs': {'deep_architecture': True, 'full': False}}\n",
      "scPhere-lvm - library size\n",
      "deep_architecture True\n",
      "full False\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:18<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecc7656b13247288b170dbd175be529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 5667.244974384633\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904e4b09d45d461090992d2dd99f88bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1621.1283879293521\n",
      "INFO:root:LFC MEAN in batch 0: -0.30483847856521606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.0265765990880028e-05\n",
      "using offset: 1.0265765990880028e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7653f2e6b64939872fb6201fa6b0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 4342.467924197323\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f542c655214ebda6e89b0b4b6d1b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1635.8254581893445\n",
      "INFO:root:LFC MEAN in batch 1: -0.17886561155319214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.301933425063908e-05\n",
      "using offset: 3.301933425063908e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.3545747559154995\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm', 'mdl_kwargs': {'deep_architecture': True}}\n",
      "scPhere-lvm\n",
      "deep_architecture True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:35<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1b2c3522c84198acb49ee1d092d682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3230.1499726055627\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7206949520e4ef5929e1910e973da2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3177.914764088439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: -0.1465771645307541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.3824994266542489e-05\n",
      "using offset: 1.3824994266542489e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7095083aff024303bfd4d7bc4b7ff520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1008.5335730350587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe5b7ed6d5c4c2bb324954f21d870b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2727.858143310024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 1: -0.06697133928537369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.7309436452705994e-05\n",
      "using offset: 1.7309436452705994e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.6685621981697291\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - constant overdispersion', 'mdl_kwargs': {'deep_architecture': True, 'constant_pxr': False, 'cell_specific_px': True}}\n",
      "scPhere-lvm - constant overdispersion\n",
      "deep_architecture True\n",
      "constant_pxr False\n",
      "cell_specific_px True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:39<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08e574a8df149e5a721934a2d91807d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2818.459967966433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c845f7ec4b4ac6801404a098628ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1594.2621330257628\n",
      "INFO:root:LFC MEAN in batch 0: -0.11810796707868576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.7663524795352716e-05\n",
      "using offset: 1.7663524795352716e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f44b82bea248deba0e72d0f671d967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2579.5847263397127\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4b2d6edd704e93818df4fc36d8b14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1652.0655384582246\n",
      "INFO:root:LFC MEAN in batch 1: -0.20907896757125854\n",
      "INFO:root:DELTA VALUE: 0.7246643580227344\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.9781485298153713e-05\n",
      "using offset: 1.9781485298153713e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm + ELBO', 'mdl_kwargs': {'deep_architecture': True}, 'trainer_kwargs': {'loss_type': 'ELBO', 'k': 1}}\n",
      "scPhere-lvm + ELBO\n",
      "deep_architecture True\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:30<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5ab9186c1541cc900c4008b767a834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24699.345710715876\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05406cafa7344ec895b15c9d8887838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24643.117369477804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: 0.00028407538775354624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.84332887531491e-05\n",
      "using offset: 2.84332887531491e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25957856d2564f8d8dc69a098d5188bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 23736.067815484515\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f65a7dceb446eeb53beffde20ff642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 24312.947640437353\n",
      "INFO:root:LFC MEAN in batch 1: 0.000418093433836475\n",
      "INFO:root:DELTA VALUE: 0.00020884994678141314\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.158486561005702e-05\n",
      "using offset: 3.158486561005702e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - library size', 'mdl_kwargs': {'deep_architecture': True, 'full': False}}\n",
      "scPhere-lvm - library size\n",
      "deep_architecture True\n",
      "full False\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:21<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c7988b72324e57a3084ef513fc4f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 1539.0101906900104\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444679a395684b7ba4f8e87d5ae55ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 1651.2865026965771\n",
      "INFO:root:LFC MEAN in batch 0: -0.10319166630506516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.1471458606138187e-05\n",
      "using offset: 1.1471458606138187e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7acf3ea17d4fc0aa0bf49ef2df42ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 4376.872811132934\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bbcebfc4634a60aa485c968ddc3ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1445.6112141240826\n",
      "INFO:root:LFC MEAN in batch 1: -0.13284330070018768\n",
      "INFO:root:DELTA VALUE: 0.4692198051997602\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 4.24075874434493e-05\n",
      "using offset: 4.24075874434493e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm', 'mdl_kwargs': {'deep_architecture': True}}\n",
      "scPhere-lvm\n",
      "deep_architecture True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:39<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ca636c973d4b23a3bea526e3858e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 4194.821695890448\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567851fcc57e411c888d4ad1e7ad1ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 1297.941702935146\n",
      "INFO:root:LFC MEAN in batch 0: 0.25348877906799316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.615206274436787e-05\n",
      "using offset: 1.615206274436787e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88daf7704773432c96221ef8c394e553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 6563.028545189355\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25563bae7a79455c819c8cadde905fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1887.6214145358065\n",
      "INFO:root:LFC MEAN in batch 1: 0.24674396216869354\n",
      "INFO:root:DELTA VALUE: 0.7207449896866077\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.6019771555875197e-05\n",
      "using offset: 1.6019771555875197e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - constant overdispersion', 'mdl_kwargs': {'deep_architecture': True, 'constant_pxr': False, 'cell_specific_px': True}}\n",
      "scPhere-lvm - constant overdispersion\n",
      "deep_architecture True\n",
      "constant_pxr False\n",
      "cell_specific_px True\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:39<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4ca6ec281a482c8eca7c9c049b50a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2852.0480797875657\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0541907575c4917b59fa7a52731bc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2182.14525234041\n",
      "INFO:root:LFC MEAN in batch 0: -0.24333243072032928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.873578130471287e-05\n",
      "using offset: 1.873578130471287e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5831bca5f64acfb81dde9b938cc426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3283.0594341475944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ff73b7f5fb496990a97d7d3991df07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1688.4732502227318\n",
      "INFO:root:LFC MEAN in batch 1: -0.2530427575111389\n",
      "INFO:root:DELTA VALUE: 0.7305556326311586\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 1.7256530736631247e-05\n",
      "using offset: 1.7256530736631247e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm + ELBO', 'mdl_kwargs': {'deep_architecture': True}, 'trainer_kwargs': {'loss_type': 'ELBO', 'k': 1}}\n",
      "scPhere-lvm + ELBO\n",
      "deep_architecture True\n",
      "loss_type ELBO\n",
      "k 1\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:35<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be255eb9eb204ce8a9d50bb426af5996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 23836.534219232228\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ae1a97b767461c83691510a4c2a375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24793.3889815421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LFC MEAN in batch 0: 6.407842738553882e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.098864649473399e-05\n",
      "using offset: 3.098864649473399e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8a2fe1a3554ad18b559ea33ba68049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 23484.203655252546\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d8b5c3e44f49e18894223819e1aa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 24660.114056049075\n",
      "INFO:root:LFC MEAN in batch 1: 7.19712843419984e-05\n",
      "INFO:root:DELTA VALUE: 3.985294584792955e-05\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 3.284917020209832e-05\n",
      "using offset: 3.284917020209832e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using Deep architecture ...\n",
      "INFO:root:Using deep architecture\n",
      "INFO:root:Using fixed LR\n",
      "INFO:root:Using learning rate 0.001\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'scPhere-lvm - library size', 'mdl_kwargs': {'deep_architecture': True, 'full': False}}\n",
      "scPhere-lvm - library size\n",
      "deep_architecture True\n",
      "full False\n",
      "\n",
      "training: 100%|██████████| 500/500 [09:23<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 115 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f1528f924548af866288cb8bb97f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([25185, 219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3356.3714464781665\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 500 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01e08d7c14f4e9486ac7cb3ad6cd4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([25000, 50])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1878.397151287346\n",
      "INFO:root:LFC MEAN in batch 0: 0.05122720077633858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 8.54279812756431e-06\n",
      "using offset: 8.54279812756431e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 109 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3a70d524e249da9cc435b29716eab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([25070, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 4171.328595027316\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 642 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92aa27b66fe847869216a2925cc0f011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([25038, 39])\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ESS: 1743.1600672471225\n",
      "INFO:root:LFC MEAN in batch 1: 0.10046479105949402\n",
      "INFO:root:DELTA VALUE: 0.2908979872935486\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inferred offsets: 1e-10 2.3760529711580602e-05\n",
      "using offset: 2.3760529711580602e-05\n"
     ]
    }
   ],
   "source": [
    "mdl_sph_kwargs = dict(\n",
    "    n_genes=dataset.nb_genes,\n",
    "    n_batches=dataset.n_batches,\n",
    "    n_latent=11,\n",
    "    dropout_rate=0.0,\n",
    "    do_depth_reg=False,\n",
    "    constant_pxr=True,\n",
    "    cell_specific_px=False,\n",
    "    use_batch_norm=False, \n",
    "    use_layer_norm=True,\n",
    "    deep_architecture=False,    \n",
    "    full=True,\n",
    ")\n",
    "trainer_sph_kwargs = dict(\n",
    "    train_library=True,\n",
    "    k=25,\n",
    "    loss_type=\"IWELBO\",\n",
    "    batch_size=1024,\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_type=\"adam\",\n",
    "    test_indices=[],\n",
    ")\n",
    "\n",
    "algos = [\n",
    "#     dict(name=\"scPhere-lvm\"),\n",
    "    dict(name=\"scPhere-lvm\", mdl_kwargs=dict(deep_architecture=True)),\n",
    "    dict(\n",
    "        name=\"scPhere-lvm - constant overdispersion\", \n",
    "        mdl_kwargs=dict(\n",
    "            deep_architecture=True,\n",
    "            constant_pxr=False,\n",
    "            cell_specific_px=True,\n",
    "        )\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"scPhere-lvm + ELBO\", \n",
    "        mdl_kwargs=dict(deep_architecture=True),\n",
    "        trainer_kwargs=dict(loss_type=\"ELBO\", k=1)\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"scPhere-lvm - library size\", \n",
    "        mdl_kwargs=dict(deep_architecture=True, full=False)\n",
    "    ),\n",
    "]\n",
    "\n",
    "from scvi.models import SCSphere, SCSphereFull\n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for iterate in range(5):\n",
    "    for algo in (algos):\n",
    "        # Overall parameters\n",
    "        print(algo)\n",
    "        algo = algo.copy()\n",
    "        algo_name = algo.pop(\"name\")\n",
    "        autolr = algo.pop(\"autolr\", True)\n",
    "        print(algo_name)\n",
    "\n",
    "        # Model parameters\n",
    "        mdl_params_iter = mdl_sph_kwargs.copy()\n",
    "        _mdl_params_iter = algo.pop(\"mdl_kwargs\", dict())\n",
    "        \n",
    "        for key, new_val in _mdl_params_iter.items():\n",
    "            print(key, new_val)\n",
    "            mdl_params_iter[key] = new_val\n",
    "\n",
    "        # Trainer parameters\n",
    "        trainer_params_iter = trainer_sph_kwargs.copy()\n",
    "        _trainer_params_iter = algo.pop(\"trainer_kwargs\", dict())\n",
    "        for key, new_val in _trainer_params_iter.items():\n",
    "            print(key, new_val)\n",
    "            trainer_params_iter[key] = new_val\n",
    "\n",
    "        print()\n",
    "        do_full = mdl_params_iter.pop(\"full\", True,)\n",
    "        if do_full:\n",
    "            mdl_iw = SCSphereFull(**mdl_params_iter)\n",
    "        else:\n",
    "            mdl_iw = SCSphere(**mdl_params_iter)\n",
    "        trainer_iw = UnsupervisedTrainer(\n",
    "            model=mdl_iw, gene_dataset=dataset, **trainer_params_iter\n",
    "        )\n",
    "#         if not autolr:\n",
    "        logging.info(\"Using fixed LR\")\n",
    "        lr_iw = 1e-3\n",
    "#         else:\n",
    "#             lr_iw = trainer_iw.find_lr()\n",
    "#             mdl_iw = SCSphere(**mdl_params_iter)\n",
    "#             trainer_iw = UnsupervisedTrainer(\n",
    "#                 model=mdl_iw, gene_dataset=dataset, **trainer_params_iter\n",
    "#             )\n",
    "        logging.info(\"Using learning rate {}\".format(lr_iw))\n",
    "        trainer_iw.train(n_epochs=N_EPOCHS, lr=1e-3)\n",
    "        mdl_iw.eval()\n",
    "\n",
    "        mf_props_eb = get_eb_full(\n",
    "            trainer=trainer_iw,\n",
    "            idx_a=idx_a,\n",
    "            mode_coeff=0.6,\n",
    "            idx_b=idx_b,\n",
    "            offset=None,\n",
    "            delta=None,\n",
    "            n_samples=50000,\n",
    "            do_batch_specific=\"separation\",\n",
    "            posterior_chunks=200,\n",
    "            do_normalize=False,\n",
    "            filter_cts=True,\n",
    "        )\n",
    "\n",
    "        \n",
    "        subres_d = {**mf_props_eb, **dict(lfc_gt=lfc_gt, is_significant_de=is_significant_de)}\n",
    "        subres_d[\"gene_idx\"] = np.arange(len(is_significant_de))\n",
    "        subres = pd.DataFrame(subres_d).assign(algo_name=algo_name, iterate=iterate)\n",
    "\n",
    "        results = results.append(subres, ignore_index=True)\n",
    "\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_pickle(\"lfc_estimates_both_rareFIXED5/symsim_ablation_study/results_sph7_.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Unique optim\n",
      "INFO:root:Automatic LR choice 0.0004641588833612781\n",
      "INFO:root:Normal parameterization of the library\n",
      "INFO:root:Scale decoder with Softmax normalization\n",
      "INFO:root:Using learning rate 0.0004641588833612781\n",
      "INFO:root:Unique optim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 500/500 [08:56<00:00,  1.07s/it]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdl_iw = VAE(n_input=dataset.nb_genes, n_batch=dataset.n_batches, **mdl_iw_kwargs)\n",
    "trainer_iw = UnsupervisedTrainer(\n",
    "    model=mdl_iw, gene_dataset=dataset, **trainer_iw_kwargs\n",
    ")\n",
    "lr_iw = trainer_iw.find_lr()\n",
    "mdl_iw = VAE(n_input=dataset.nb_genes, n_batch=dataset.n_batches, **mdl_iw_kwargs)\n",
    "trainer_iw = UnsupervisedTrainer(\n",
    "    model=mdl_iw, gene_dataset=dataset, **trainer_iw_kwargs\n",
    ")\n",
    "logging.info(\"Using learning rate {}\".format(lr_iw))\n",
    "trainer_iw.train(n_epochs=500, lr=1e-2)\n",
    "mdl_iw.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = None\n",
    "\n",
    "base_features = dict(\n",
    "    trainer=trainer_iw,\n",
    "    idx_a=idx_a,\n",
    "    mode_coeff=0.6,\n",
    "    idx_b=idx_b,\n",
    "    offset=None,\n",
    "    delta=delta,\n",
    "    n_samples=20000,\n",
    "    do_batch_specific=\"separation\",\n",
    "    posterior_chunks=200,\n",
    "    do_normalize=True,\n",
    "#     do_normalize=True,\n",
    "    filter_cts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    dict(name=\"Reference\"),\n",
    "    dict(name=\"Reference - outliers\", filter_cts=False),\n",
    "    dict(name=\"Reference - pseudocounts\", offset=1e-12),\n",
    "    dict(name=\"Reference - autolr\", delta=.8),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22f49402cc749c4ac108c2bdc9285b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3296.0246309690538\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283db50dc34940ebae671ad315fd3b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 543.3414979817777\n",
      "INFO:root:LFC MEAN in batch 0: 0.057838473469018936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.1667792932712473e-05\n",
      "using offset: 1.1667792932712473e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92122cb00bb34527a1a3a2c5196176bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1650.5962112283478\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba85045fd904a6ea058c93be0c95d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 660.6414725264499\n",
      "INFO:root:LFC MEAN in batch 1: -0.04239825904369354\n",
      "INFO:root:DELTA VALUE: 0.7415488183268154\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2137251360400114e-05\n",
      "using offset: 1.2137251360400114e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Using 41 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "filter_cts False\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06d1d2f3b454a82b46bc0b7d6848740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2806.005417363001\n",
      "INFO:root:Using 179 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 244])\n",
      "torch.Size([10004, 244])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f8ffab03cf49e3a0cf3f046d5f7caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 185.21206041124375\n",
      "INFO:root:LFC MEAN in batch 0: 0.05151665210723877\n",
      "INFO:root:Using 40 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 56])\n",
      "torch.Size([10024, 56])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.1117255507997471e-05\n",
      "using offset: 1.1117255507997471e-05\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf7956bf3e341e0b51171ec749bdc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 417.3768975123467\n",
      "INFO:root:Using 228 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([10240, 256])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af598eee03a4a48bb917061d98da59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 283.8997410510584\n",
      "INFO:root:LFC MEAN in batch 1: 0.10880076885223389\n",
      "INFO:root:DELTA VALUE: 0.7201484668742862\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 44])\n",
      "torch.Size([10032, 44])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.243714536940388e-05\n",
      "using offset: 1.243714536940388e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "offset 1e-12\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6f7999485d4dde8e678f84d1e5955f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2491.9367440683877\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d927a9d967a4761a35d2bdd7eaba6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 452.09649065189967\n",
      "INFO:root:LFC MEAN in batch 0: 0.048026394098997116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "using offset: 1e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ec36c59571454c83567fa526c096a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2955.248320845393\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42b5923e3c546a7b37bed102d9e25e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 684.9006242290823\n",
      "INFO:root:LFC MEAN in batch 1: -0.014296511188149452\n",
      "INFO:root:DELTA VALUE: 0.7443068140883655\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "using offset: 1e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "delta 0.8\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a7a9723b2641b381dfb0b07487d474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3779.708877477318\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b40df2e48534445ab9ff84b1ffcfd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 226.70951338425039\n",
      "INFO:root:LFC MEAN in batch 0: 0.05195700749754906\n",
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.1272304527665256e-05\n",
      "using offset: 1.1272304527665256e-05\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae5d8e8b3b84a2b95e6738c1374b3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 565.1762825223924\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37f37c4e1d346ce891ade8d0b301207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 590.2864898611167\n",
      "INFO:root:LFC MEAN in batch 1: 0.002981869038194418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2269739636394663e-05\n",
      "using offset: 1.2269739636394663e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39028ed602fe48acbb7962b73ef019ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2279.573687813722\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3752836d5f24f9d8c07ced19edf3b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 220.70288448276818\n",
      "INFO:root:LFC MEAN in batch 0: 0.04695728421211243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.2174968196632109e-05\n",
      "using offset: 1.2174968196632109e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f2d4eb5fcb419690242105f93976d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1453.847905533355\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032cf950dcbf4819beaef3af756647be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 712.4152355844085\n",
      "INFO:root:LFC MEAN in batch 1: 0.0006576384184882045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.4513212408928667e-05\n",
      "using offset: 1.4513212408928667e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DELTA VALUE: 0.705617845416063\n",
      "INFO:root:Using mode coefficient 0.6\n",
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Using 41 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "filter_cts False\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd7334d1ba342dcb19c150095976d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3596.311049362571\n",
      "INFO:root:Using 179 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 244])\n",
      "torch.Size([10004, 244])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747a2d8a778f40c8bfda43f235c90f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 659.776108534073\n",
      "INFO:root:LFC MEAN in batch 0: 0.060012128204107285\n",
      "INFO:root:Using 40 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 56])\n",
      "torch.Size([10024, 56])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.1260272367508151e-05\n",
      "using offset: 1.1260272367508151e-05\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f6ce7e6fe446a5b81a330640dbbc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 237.38982270299692\n",
      "INFO:root:Using 228 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([10240, 256])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4be0f3f527a4322a7675dddc6668715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 450.51345246559134\n",
      "INFO:root:LFC MEAN in batch 1: 0.09093952178955078\n",
      "INFO:root:DELTA VALUE: 0.7248607460818162\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 44])\n",
      "torch.Size([10032, 44])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2374082734822877e-05\n",
      "using offset: 1.2374082734822877e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "offset 1e-12\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f89c1e9224343abba6f52aa58706129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2706.5512404622095\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b45d201d8e48a88e4883286ee629d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 311.77235958377383\n",
      "INFO:root:LFC MEAN in batch 0: 0.03131954371929169\n",
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "using offset: 1e-12\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5789663bc16f46148526712d5e09298b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 261.42388760549784\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1704859f85fb4f87be1b70453239b565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 493.29654802344504\n",
      "INFO:root:LFC MEAN in batch 1: -0.057579729706048965\n",
      "INFO:root:DELTA VALUE: 0.7463661706219271\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "using offset: 1e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "delta 0.8\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560d1ecb8f7245249fae46f24aa2fa63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3769.5173146789807\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef649b05f4846889c599d9f37a0e2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 351.59815438624696\n",
      "INFO:root:LFC MEAN in batch 0: 0.04778438061475754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.1536733472894411e-05\n",
      "using offset: 1.1536733472894411e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6f27c5053a4c508da22df835e24aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2864.3345754992156\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e6f95161f4e81837a7fa2e3cdb116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 708.0110862687169\n",
      "INFO:root:LFC MEAN in batch 1: -0.010431409813463688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.1859070082209654e-05\n",
      "using offset: 1.1859070082209654e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76b2a659ec44b3d845bbb4e665542d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2991.8001211531546\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd3c309a8e948ab9cdca5fcf6bebfda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 219.86850872318954\n",
      "INFO:root:LFC MEAN in batch 0: 0.03373940661549568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.3126071462465917e-05\n",
      "using offset: 1.3126071462465917e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375296c76e934c42b10b57122b5398f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2418.671438722042\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac2c79e571e4e3e9703f896b04c7f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1001.4458227091636\n",
      "INFO:root:LFC MEAN in batch 1: 0.000214019586564973\n",
      "INFO:root:DELTA VALUE: 0.7358726416762327\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2080380611223519e-05\n",
      "using offset: 1.2080380611223519e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Using 41 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "filter_cts False\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2793f48410d4641ac13390358bf99a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3174.1792746871224\n",
      "INFO:root:Using 179 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 244])\n",
      "torch.Size([10004, 244])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da177b51e870450cb519c661c5a39720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 330.4933742691674\n",
      "INFO:root:LFC MEAN in batch 0: 0.047542985528707504\n",
      "INFO:root:Using 40 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 56])\n",
      "torch.Size([10024, 56])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.2331952257227387e-05\n",
      "using offset: 1.2331952257227387e-05\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16eb3d55d29641bd9f135537859942a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 520.6664697938412\n",
      "INFO:root:Using 228 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([10240, 256])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81a7917773e4103b419e973ea94817e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 173.39086385076143\n",
      "INFO:root:LFC MEAN in batch 1: 0.11433849483728409\n",
      "INFO:root:DELTA VALUE: 0.7278797717419633\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 44])\n",
      "torch.Size([10032, 44])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2315417870922831e-05\n",
      "using offset: 1.2315417870922831e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "offset 1e-12\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddac610d7ef49efb127e229476449dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3172.183026752804\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68439674a624fa7ab0d222fad538704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 259.5207558365424\n",
      "INFO:root:LFC MEAN in batch 0: 0.02448143996298313\n",
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "using offset: 1e-12\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4c402b23bf4896820874e075e29731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1498.0698194794682\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed75514beb614477a588d315f11b8286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 242.5124239016193\n",
      "INFO:root:LFC MEAN in batch 1: -0.07281819730997086\n",
      "INFO:root:DELTA VALUE: 0.7433214097837954\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "using offset: 1e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "delta 0.8\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a4da5cdf25407392bd0403c14bbe3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3453.6770399390234\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aaf3beece954395a74829ff4dc746ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 350.71570605080245\n",
      "INFO:root:LFC MEAN in batch 0: 0.036950889974832535\n",
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.0485901384527098e-05\n",
      "using offset: 1.0485901384527098e-05\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613c6a199b7c4d129fc9945c06e536db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2937.108586739948\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada0d4b2990541478ac9c2e67ab223ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 166.68480211122753\n",
      "INFO:root:LFC MEAN in batch 1: 0.049248941242694855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2533513745438542e-05\n",
      "using offset: 1.2533513745438542e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071414ec684442c5bec00e38666db70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2922.450233593668\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc7ce720dca4cc592b8f3f015622fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 55.49777262936003\n",
      "INFO:root:LFC MEAN in batch 0: 0.052603740245103836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.1983025160589023e-05\n",
      "using offset: 1.1983025160589023e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b93528f13ea41b881b1c7a8b68e472c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2697.2984315749604\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9365b76e4a2e46c1ac6fa77010211b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 662.5713372233791\n",
      "INFO:root:LFC MEAN in batch 1: -0.04402153193950653\n",
      "INFO:root:DELTA VALUE: 0.7401443657609651\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2595314456120833e-05\n",
      "using offset: 1.2595314456120833e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Using 41 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "filter_cts False\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d3ee12c5d5434692197c0f35717567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1951.6435376591687\n",
      "INFO:root:Using 179 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 244])\n",
      "torch.Size([10004, 244])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a658dfc8dd4142ea83f4724c85e97fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 100.89290302405699\n",
      "INFO:root:LFC MEAN in batch 0: 0.03517737239599228\n",
      "INFO:root:Using 40 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 56])\n",
      "torch.Size([10024, 56])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.2412814066919964e-05\n",
      "using offset: 1.2412814066919964e-05\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf89753cc334236a26acfa6594272fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 552.8296173225042\n",
      "INFO:root:Using 228 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([10240, 256])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c29859bdb4b4e1c8bb949d4d23cda39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 553.2053368299096\n",
      "INFO:root:LFC MEAN in batch 1: 0.08181182295084\n",
      "INFO:root:DELTA VALUE: 0.726512833732361\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 44])\n",
      "torch.Size([10032, 44])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2253367685843841e-05\n",
      "using offset: 1.2253367685843841e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "offset 1e-12\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c205898807d14a078b00f84fb61cab6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2739.3524099269594\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2dbb210b8d4e5795f1271b19eb95bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 472.2297954751135\n",
      "INFO:root:LFC MEAN in batch 0: 0.03791942819952965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "using offset: 1e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9798465de14b5f802ff3787745271b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 1517.5726341586824\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f414a68904e2454f90f22a621cc5b5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 510.30670510095536\n",
      "INFO:root:LFC MEAN in batch 1: -0.05227925255894661\n",
      "INFO:root:DELTA VALUE: 0.7470889434697251\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "using offset: 1e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "delta 0.8\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28994f1c888487aa6b962710168add4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3463.2388775109807\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7870dc673d1a4fa18249cce92fc7462f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3.7853862326934524\n",
      "INFO:root:LFC MEAN in batch 0: 0.008678457699716091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.08822599031555e-05\n",
      "using offset: 1.08822599031555e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20999968334446ea2a0ac7bd0226d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2380.480628518181\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7136335237884bf2a0607f77441d7b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 374.78727025998046\n",
      "INFO:root:LFC MEAN in batch 1: -0.034804679453372955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2701627201749944e-05\n",
      "using offset: 1.2701627201749944e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28c93272be84ea2b7b8eaaa913e9c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2562.0714914359723\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6ce1969f4e48329d24a2e2343ceb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 330.76955806386127\n",
      "INFO:root:LFC MEAN in batch 0: 0.045590732246637344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.3448312256514327e-05\n",
      "using offset: 1.3448312256514327e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48688ec35a546a2986d130208371925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2279.596978515829\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdf7232bf184fb5bf08a0c38bccc66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 92.69307339422218\n",
      "INFO:root:LFC MEAN in batch 1: -0.008044256828725338\n",
      "INFO:root:DELTA VALUE: 0.7440202864202795\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.238137315340282e-05\n",
      "using offset: 1.238137315340282e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Using 41 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "filter_cts False\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1012f4df8caf420793d189517bdfd6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3855.672242920871\n",
      "INFO:root:Using 179 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 244])\n",
      "torch.Size([10004, 244])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1134832ad19b47b6b52f30f3a7f9c4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 153.8003146072952\n",
      "INFO:root:LFC MEAN in batch 0: 0.05158264562487602\n",
      "INFO:root:Using 40 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 56])\n",
      "torch.Size([10024, 56])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.1575998632906705e-05\n",
      "using offset: 1.1575998632906705e-05\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbc1e22657b402fb7a1b9d57da18256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 671.7404381438865\n",
      "INFO:root:Using 228 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([10240, 256])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcb30e6b4f64e23836c3287ec991ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "INFO:root:ESS: 844.7193909320306\n",
      "INFO:root:LFC MEAN in batch 1: 0.07241260260343552\n",
      "INFO:root:DELTA VALUE: 0.727637617159478\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 44])\n",
      "torch.Size([10032, 44])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.2296745853745961e-05\n",
      "using offset: 1.2296745853745961e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "offset 1e-12\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a20ace40a96470faf9821a46a432bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3369.4134330200914\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a3745e9ff143559f608ded718a69ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 288.27713906621926\n",
      "INFO:root:LFC MEAN in batch 0: 0.035600822418928146\n",
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "using offset: 1e-12\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a324888219420eb361a08a5abbb17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2742.3218886281607\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1c289819cf4b4e970531521d20b9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 309.4756395061956\n",
      "INFO:root:LFC MEAN in batch 1: 0.05414086580276489\n",
      "INFO:root:DELTA VALUE: 0.771492193443817\n",
      "INFO:root:Using mode coefficient 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "using offset: 1e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pop A 500 & Pop B 100\n",
      "INFO:root:Using mode separation\n",
      "INFO:root:Filtering observations: Keeping (219,) cells from original 244 sample size\n",
      "INFO:root:Using 46 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "delta 0.8\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7703de3903144feca31cee35c617d501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 3582.8909987833094\n",
      "INFO:root:Filtering observations: Keeping (50,) cells from original 56 sample size\n",
      "INFO:root:Using 200 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 219])\n",
      "torch.Size([10074, 219])\n",
      "tensor([0])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3f03d39b4941a78e9090560e78a8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 86.69883401594802\n",
      "INFO:root:LFC MEAN in batch 0: 0.047584258019924164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([10000, 50])\n",
      "tensor([0])\n",
      "Data inferred offsets: 1e-10 1.4042660313862144e-05\n",
      "using offset: 1.4042660313862144e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering observations: Keeping (230,) cells from original 256 sample size\n",
      "INFO:root:Using 44 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913318dad7aa46f1b4bf5bd070a1a75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 2604.676488757165\n",
      "INFO:root:Filtering observations: Keeping (39,) cells from original 44 sample size\n",
      "INFO:root:Using 257 posterior samples per cell\n",
      "INFO:root:Step 1: Getting posterior samples\n",
      "INFO:root:Step 2: Compute overall importance weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 230])\n",
      "torch.Size([10120, 230])\n",
      "tensor([1])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83e4083a72e462fbaf8aa04785a2045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using 5000 samples for log-evidence estimation ...\n",
      "INFO:root:... done!\n",
      "INFO:root:px reweight\n",
      "INFO:root:Step 3: Compute scales from original batches\n",
      "/data/yosef2/users/pierreboyeau/scVI-DE/scvi/inference/posterior.py:401: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "INFO:root:ESS: 661.2949648972105\n",
      "INFO:root:LFC MEAN in batch 1: -0.0380527526140213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39])\n",
      "torch.Size([10023, 39])\n",
      "tensor([1])\n",
      "Data inferred offsets: 1e-10 1.290798136324156e-05\n",
      "using offset: 1.290798136324156e-05\n"
     ]
    }
   ],
   "source": [
    "res_feat = pd.DataFrame()\n",
    "\n",
    "for iterate in range(5):\n",
    "    for feat in features:\n",
    "        feat = feat.copy()\n",
    "        algo_name = feat.pop(\"name\")\n",
    "        iter_feats = base_features.copy()\n",
    "        print(\"\\n\\n\\n\")\n",
    "        for key, new_val in feat.items():\n",
    "            print(key, new_val)\n",
    "            iter_feats[key] = new_val\n",
    "        mf_props_eb = get_eb_full(\n",
    "            **iter_feats\n",
    "        )\n",
    "\n",
    "\n",
    "        subres_d = {**mf_props_eb, **dict(lfc_gt=lfc_gt, is_significant_de=is_significant_de)}\n",
    "        subres_d[\"gene_idx\"] = np.arange(len(is_significant_de))\n",
    "        subres = pd.DataFrame(subres_d).assign(algo_name=algo_name, iterate=iterate)\n",
    "\n",
    "        res_feat = res_feat.append(subres, ignore_index=True)\n",
    "\n",
    "\n",
    "res_feat.to_pickle(\"lfc_estimates_both_rareFIXED5/symsim_ablation_study/results_features.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['symsim_bimod_100_500_1e-10_0.8_2000_4',\n",
       " 'results_sph7.pickle',\n",
       " 'results_iw6.pickle',\n",
       " 'results_scvi.pickle',\n",
       " 'symsim_bimod_100_500_1e-10_0.8_2000_3',\n",
       " 'results_sph3.pickle',\n",
       " 'symsim_bimod_100_500_1e-10_0.8_2000_0',\n",
       " 'symsim_bimod_100_500_1e-10_0.8_2000_2',\n",
       " 'results_iw3.pickle',\n",
       " 'results_sph2.pickle',\n",
       " 'results_features.pickle',\n",
       " 'symsim_bimod_100_500_1e-10_0.8_2000_1',\n",
       " 'results_sph6.pickle',\n",
       " 'results_iw7.pickle',\n",
       " 'results_iw5.pickle']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"lfc_estimates_both_rareFIXED5/symsim_ablation_study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_pickle(\"lfc_estimates_both_rareFIXED5/symsim_ablation_study/results_iw7.pickle\")\n",
    "# results = pd.read_pickle(\"lfc_estimates_both_rareFIXED5/symsim_ablation_study/results_sph7.pickle\")\n",
    "results = pd.read_pickle(\"lfc_estimates_both_rareFIXED5/symsim_ablation_study/results_features.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de_score</th>\n",
       "      <th>lfc_estim</th>\n",
       "      <th>lfc_std</th>\n",
       "      <th>filt_opt_full_eb_ppos</th>\n",
       "      <th>filt_opt_full_eb_pneg</th>\n",
       "      <th>lfc_estim2</th>\n",
       "      <th>khat_a0</th>\n",
       "      <th>khat_b0</th>\n",
       "      <th>khat_a1</th>\n",
       "      <th>khat_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>opt_full_eb_lfc_std</th>\n",
       "      <th>opt_full_eb_ppos</th>\n",
       "      <th>opt_full_eb_pneg</th>\n",
       "      <th>opt_full_eb_lfc_estim2</th>\n",
       "      <th>filt_full_eb_is_de2</th>\n",
       "      <th>filt_full_eb_lfc_estim</th>\n",
       "      <th>filt_full_eb_lfc_std</th>\n",
       "      <th>filt_full_eb_ppos</th>\n",
       "      <th>filt_full_eb_pneg</th>\n",
       "      <th>filt_full_eb_lfc_estim2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.054405</td>\n",
       "      <td>0.171949</td>\n",
       "      <td>0.57975</td>\n",
       "      <td>0.42025</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.340707</td>\n",
       "      <td>0.476626</td>\n",
       "      <td>0.553424</td>\n",
       "      <td>0.551720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00060</td>\n",
       "      <td>-0.227768</td>\n",
       "      <td>0.146223</td>\n",
       "      <td>0.06315</td>\n",
       "      <td>0.93685</td>\n",
       "      <td>-0.199001</td>\n",
       "      <td>0.340707</td>\n",
       "      <td>0.476626</td>\n",
       "      <td>0.553424</td>\n",
       "      <td>0.551720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01055</td>\n",
       "      <td>0.162581</td>\n",
       "      <td>0.234749</td>\n",
       "      <td>0.76320</td>\n",
       "      <td>0.23680</td>\n",
       "      <td>0.085583</td>\n",
       "      <td>0.340707</td>\n",
       "      <td>0.476626</td>\n",
       "      <td>0.553424</td>\n",
       "      <td>0.551720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.885982</td>\n",
       "      <td>0.237773</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.885982</td>\n",
       "      <td>0.340707</td>\n",
       "      <td>0.476626</td>\n",
       "      <td>0.553424</td>\n",
       "      <td>0.551720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.026363</td>\n",
       "      <td>0.143219</td>\n",
       "      <td>0.42275</td>\n",
       "      <td>0.57725</td>\n",
       "      <td>-0.004073</td>\n",
       "      <td>0.340707</td>\n",
       "      <td>0.476626</td>\n",
       "      <td>0.553424</td>\n",
       "      <td>0.551720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451896</td>\n",
       "      <td>0.522118</td>\n",
       "      <td>0.496633</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.246451</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>0.00045</td>\n",
       "      <td>0.99955</td>\n",
       "      <td>-0.246229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451896</td>\n",
       "      <td>0.522118</td>\n",
       "      <td>0.496633</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>-0.226437</td>\n",
       "      <td>0.179491</td>\n",
       "      <td>0.11655</td>\n",
       "      <td>0.88345</td>\n",
       "      <td>-0.173655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451896</td>\n",
       "      <td>0.522118</td>\n",
       "      <td>0.496633</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>-0.259671</td>\n",
       "      <td>0.226709</td>\n",
       "      <td>0.14755</td>\n",
       "      <td>0.85245</td>\n",
       "      <td>-0.183042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451896</td>\n",
       "      <td>0.522118</td>\n",
       "      <td>0.496633</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99850</td>\n",
       "      <td>-1.508290</td>\n",
       "      <td>0.234565</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.508290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451896</td>\n",
       "      <td>0.522118</td>\n",
       "      <td>0.496633</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>-0.275787</td>\n",
       "      <td>0.240427</td>\n",
       "      <td>0.16040</td>\n",
       "      <td>0.83960</td>\n",
       "      <td>-0.187314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      de_score  lfc_estim   lfc_std  filt_opt_full_eb_ppos  \\\n",
       "0      0.00000   0.054405  0.171949                0.57975   \n",
       "1      0.00060  -0.227768  0.146223                0.06315   \n",
       "2      0.01055   0.162581  0.234749                0.76320   \n",
       "3      1.00000  -1.885982  0.237773                0.00000   \n",
       "4      0.00000  -0.026363  0.143219                0.42275   \n",
       "...        ...        ...       ...                    ...   \n",
       "7915   0.00000   0.000000  0.000000                0.00000   \n",
       "7916   0.00000   0.000000  0.000000                0.00000   \n",
       "7917   0.00000   0.000000  0.000000                0.00000   \n",
       "7918   0.00000   0.000000  0.000000                0.00000   \n",
       "7919   0.00000   0.000000  0.000000                0.00000   \n",
       "\n",
       "      filt_opt_full_eb_pneg  lfc_estim2   khat_a0   khat_b0   khat_a1  \\\n",
       "0                   0.42025    0.008678  0.340707  0.476626  0.553424   \n",
       "1                   0.93685   -0.199001  0.340707  0.476626  0.553424   \n",
       "2                   0.23680    0.085583  0.340707  0.476626  0.553424   \n",
       "3                   1.00000   -1.885982  0.340707  0.476626  0.553424   \n",
       "4                   0.57725   -0.004073  0.340707  0.476626  0.553424   \n",
       "...                     ...         ...       ...       ...       ...   \n",
       "7915                0.00000    0.000000  0.451896  0.522118  0.496633   \n",
       "7916                0.00000    0.000000  0.451896  0.522118  0.496633   \n",
       "7917                0.00000    0.000000  0.451896  0.522118  0.496633   \n",
       "7918                0.00000    0.000000  0.451896  0.522118  0.496633   \n",
       "7919                0.00000    0.000000  0.451896  0.522118  0.496633   \n",
       "\n",
       "       khat_b1  ...  opt_full_eb_lfc_std  opt_full_eb_ppos  opt_full_eb_pneg  \\\n",
       "0     0.551720  ...                  0.0               0.0               0.0   \n",
       "1     0.551720  ...                  0.0               0.0               0.0   \n",
       "2     0.551720  ...                  0.0               0.0               0.0   \n",
       "3     0.551720  ...                  0.0               0.0               0.0   \n",
       "4     0.551720  ...                  0.0               0.0               0.0   \n",
       "...        ...  ...                  ...               ...               ...   \n",
       "7915  0.521388  ...                  0.0               0.0               0.0   \n",
       "7916  0.521388  ...                  0.0               0.0               0.0   \n",
       "7917  0.521388  ...                  0.0               0.0               0.0   \n",
       "7918  0.521388  ...                  0.0               0.0               0.0   \n",
       "7919  0.521388  ...                  0.0               0.0               0.0   \n",
       "\n",
       "     opt_full_eb_lfc_estim2  filt_full_eb_is_de2  filt_full_eb_lfc_estim  \\\n",
       "0                       0.0              0.00000                0.000000   \n",
       "1                       0.0              0.00000                0.000000   \n",
       "2                       0.0              0.00000                0.000000   \n",
       "3                       0.0              0.00000                0.000000   \n",
       "4                       0.0              0.00000                0.000000   \n",
       "...                     ...                  ...                     ...   \n",
       "7915                    0.0              0.00000               -0.246451   \n",
       "7916                    0.0              0.00070               -0.226437   \n",
       "7917                    0.0              0.00155               -0.259671   \n",
       "7918                    0.0              0.99850               -1.508290   \n",
       "7919                    0.0              0.00175               -0.275787   \n",
       "\n",
       "      filt_full_eb_lfc_std  filt_full_eb_ppos  filt_full_eb_pneg  \\\n",
       "0                 0.000000            0.00000            0.00000   \n",
       "1                 0.000000            0.00000            0.00000   \n",
       "2                 0.000000            0.00000            0.00000   \n",
       "3                 0.000000            0.00000            0.00000   \n",
       "4                 0.000000            0.00000            0.00000   \n",
       "...                    ...                ...                ...   \n",
       "7915              0.093862            0.00045            0.99955   \n",
       "7916              0.179491            0.11655            0.88345   \n",
       "7917              0.226709            0.14755            0.85245   \n",
       "7918              0.234565            0.00000            1.00000   \n",
       "7919              0.240427            0.16040            0.83960   \n",
       "\n",
       "      filt_full_eb_lfc_estim2  \n",
       "0                    0.000000  \n",
       "1                    0.000000  \n",
       "2                    0.000000  \n",
       "3                    0.000000  \n",
       "4                    0.000000  \n",
       "...                       ...  \n",
       "7915                -0.246229  \n",
       "7916                -0.173655  \n",
       "7917                -0.183042  \n",
       "7918                -1.508290  \n",
       "7919                -0.187314  \n",
       "\n",
       "[7920 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiments_utils import plot_tprfdr_curves, predict_de_genes\n",
    "\n",
    "gene_idx = (\n",
    "    results\n",
    "    .groupby([\"algo_name\", \"iterate\"])\n",
    "    .apply(lambda x: pd.Series(np.arange(len(x))))\n",
    "    .T\n",
    "    .unstack()\n",
    "    .reset_index()\n",
    ")\n",
    "gene_idx\n",
    "\n",
    "rename_cols = dict(\n",
    "    filt_opt_full_eb_is_de2=\"de_score\",\n",
    "    filt_opt_full_eb_lfc_estim=\"lfc_estim\",\n",
    "    filt_opt_full_eb_lfc_std=\"lfc_std\",\n",
    "    filt_opt_full_eb_lfc_estim2=\"lfc_estim2\",\n",
    "#     opt_full_eb_is_de2=\"de_score\",\n",
    "#     opt_full_eb_lfc_estim=\"lfc_estim\",\n",
    "#     opt_full_eb_lfc_std=\"lfc_std\",\n",
    "#     opt_full_eb_lfc_estim2=\"lfc_estim2\",\n",
    ")\n",
    "\n",
    "res1d = (\n",
    "    results\n",
    "    .assign(gene_idx=lambda x: gene_idx.level_2.values)\n",
    "    .rename(columns=rename_cols).fillna(0.)\n",
    ")\n",
    "\n",
    "\n",
    "# preds01 = (\n",
    "#     results\n",
    "#     .groupby(\"algo_name\")\n",
    "#     .apply(lambda x: pd.Series(predict_de_genes(x.de_score.values, desired_fdr=0.1)))\n",
    "#     .T\n",
    "#     .stack()\n",
    "#     .reset_index()\n",
    "#     .rename(columns={\"level_0\": \"gene_idx\", 0: \"preds01\"})\n",
    "# )\n",
    "\n",
    "# preds005 = (\n",
    "#     results\n",
    "#     .groupby(\"algo_name\")\n",
    "#     .apply(lambda x: pd.Series(predict_de_genes(x.de_score.values, desired_fdr=0.05)))\n",
    "#     .T\n",
    "#     .stack()\n",
    "#     .reset_index()\n",
    "#     .rename(columns={\"level_0\": \"gene_idx\", 0: \"preds005\"})\n",
    "# )\n",
    "\n",
    "# preds02 = (\n",
    "#     results\n",
    "#     .groupby(\"algo_name\")\n",
    "#     .apply(lambda x: pd.Series(predict_de_genes(x.de_score.values, desired_fdr=0.2)))\n",
    "#     .T\n",
    "#     .stack()\n",
    "#     .reset_index()\n",
    "#     .rename(columns={\"level_0\": \"gene_idx\", 0: \"preds02\"})\n",
    "# )\n",
    "# preds01\n",
    "# res1d = res1d.merge(preds01, on=[\"gene_idx\", \"algo_name\"])\n",
    "# res1d = res1d.merge(preds02, on=[\"gene_idx\", \"algo_name\"])\n",
    "# res1d = res1d.merge(preds005, on=[\"gene_idx\", \"algo_name\"])\n",
    "res1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algo_name\n",
       "Reference                   0.027676\n",
       "Reference - autolr          0.318533\n",
       "Reference - outliers        0.318533\n",
       "Reference - pseudocounts    0.029191\n",
       "Name: FDR MAE, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotnine as p9\n",
    "\n",
    "from scvi_utils import true_fdr, posterior_expected_fdr\n",
    "\n",
    "def get_fdrs(my_df):\n",
    "    true_fdr_arr = true_fdr(y_true=my_df.is_significant_de.values, y_pred=my_df.de_score.values)\n",
    "    pe_fdr_arr, y_decision_rule = posterior_expected_fdr(y_pred=my_df.de_score.values)\n",
    "    return pd.DataFrame(dict(PEFDR=pe_fdr_arr, FDR=true_fdr_arr))\n",
    "\n",
    "fdrs_df = res1d.groupby([\"algo_name\", \"iterate\"]).apply(get_fdrs).reset_index().rename(columns={\"level_2\": \"gene_idx\"})\n",
    "fdrs_df\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "(\n",
    "    p9.ggplot(fdrs_df)\n",
    "    + p9.geom_line(p9.aes(x=\"gene_idx\", y=\"PEFDR\"))\n",
    "    + p9.geom_line(p9.aes(x=\"gene_idx\", y=\"FDR\"))\n",
    "    + p9.facet_wrap(\"algo_name\")\n",
    "#     + p9.theme(figure_size=(15, 5))\n",
    ")\n",
    "\n",
    "fdr_info =  (\n",
    "    fdrs_df\n",
    "    .groupby([\"algo_name\", \"iterate\"])\n",
    "    .apply(lambda x: np.median(np.abs(x.FDR - x.PEFDR)))\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"FDR MAE\"})\n",
    "    .groupby(\"algo_name\")\n",
    "    [\"FDR MAE\"].mean()\n",
    ")\n",
    "# fdr_info.name = \"FDR MAE\"\n",
    "fdr_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algo_name\n",
       "Reference                   0.101857\n",
       "Reference - autolr          0.728506\n",
       "Reference - outliers        0.728506\n",
       "Reference - pseudocounts    0.127879\n",
       "Name: Ranking score, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# def prerec(my_df):\n",
    "    \n",
    "\n",
    "ranks_info = (\n",
    "    res1d\n",
    "    .groupby([\"algo_name\", \"iterate\"])\n",
    "#     .apply(lambda x: pearsonr(x.lfc_gt, x.lfc_estim)[0])\n",
    "#     .apply(lambda x: np.linalg.norm(x.lfc_gt - x.lfc_estim))\n",
    "    .apply(lambda x: ((x.lfc_estim - x.lfc_gt) ** 2).mean())\n",
    "#     .apply(lambda x: roc_auc_score(x.is_significant_de, x.de_score))\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Ranking score\"})\n",
    "    .groupby(\"algo_name\")\n",
    "    [\"Ranking score\"]\n",
    "    .mean()\n",
    ")\n",
    "ranks_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algo_name\n",
       "Reference                   0.504135\n",
       "Reference - autolr          0.514178\n",
       "Reference - outliers        0.542678\n",
       "Reference - pseudocounts    0.541821\n",
       "Name: khat, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stab_info = (\n",
    "    res1d\n",
    "    .groupby([\"algo_name\", \"iterate\"])\n",
    "    .apply(lambda x: np.mean(x[[\"khat_a0\", \"khat_b0\", \"khat_a1\", \"khat_b1\"]].values))\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Ranking score\"})\n",
    "    .groupby(\"algo_name\")\n",
    "    [\"Ranking score\"]\n",
    "    .mean()\n",
    ")\n",
    "stab_info.name = \"khat\"\n",
    "stab_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algo_name\n",
       "Reference                   0.079291\n",
       "Reference - autolr          0.000000\n",
       "Reference - outliers        0.000000\n",
       "Reference - pseudocounts    0.148819\n",
       "Name: NC, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_genes = np.where(~is_significant_de)[0]\n",
    "null_info = (\n",
    "    res1d\n",
    "    .groupby([\"algo_name\", \"iterate\"])\n",
    "    .apply(lambda x: np.mean(x.loc[lambda y: y.gene_idx.isin(null_genes)].lfc_estim**2))\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"Ranking score\"})\n",
    "    .groupby(\"algo_name\")\n",
    "    [\"Ranking score\"]\n",
    "    .mean()\n",
    ")\n",
    "null_info.name = \"NC\"\n",
    "null_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FDR MAE</th>\n",
       "      <th>Ranking score</th>\n",
       "      <th>khat</th>\n",
       "      <th>NC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ref</th>\n",
       "      <td>0.027676</td>\n",
       "      <td>0.101857</td>\n",
       "      <td>0.504135</td>\n",
       "      <td>0.079291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref - autolr</th>\n",
       "      <td>0.318533</td>\n",
       "      <td>0.728506</td>\n",
       "      <td>0.514178</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref - outliers</th>\n",
       "      <td>0.318533</td>\n",
       "      <td>0.728506</td>\n",
       "      <td>0.542678</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref - pseudocounts</th>\n",
       "      <td>0.029191</td>\n",
       "      <td>0.127879</td>\n",
       "      <td>0.541821</td>\n",
       "      <td>0.148819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FDR MAE  Ranking score      khat        NC\n",
       "new_index                                                      \n",
       "Ref                 0.027676       0.101857  0.504135  0.079291\n",
       "Ref - autolr        0.318533       0.728506  0.514178  0.000000\n",
       "Ref - outliers      0.318533       0.728506  0.542678  0.000000\n",
       "Ref - pseudocounts  0.029191       0.127879  0.541821  0.148819"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_res = (\n",
    "    pd.concat([\n",
    "        fdr_info, \n",
    "        ranks_info, \n",
    "        stab_info,\n",
    "        null_info\n",
    "    ], axis=1)\n",
    "    .assign(new_index=lambda x: x.index.str.replace(\"Reference\", \"Ref\"))\n",
    "    .set_index(\"new_index\")\n",
    ")\n",
    "agg_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref & 0.0277 & 0.1019 & 0.5041 & 0.0793 \\\\\n",
      "Ref - autolr & 0.3185 & 0.7285 & 0.5142 & 0.0000 \\\\\n",
      "Ref - outliers & 0.3185 & 0.7285 & 0.5427 & 0.0000 \\\\\n",
      "Ref - pseudocounts & 0.0292 & 0.1279 & 0.5418 & 0.1488 \\\\\n"
     ]
    }
   ],
   "source": [
    "for row in agg_res.iterrows():\n",
    "    row_vals = [\"{0:.4f}\".format(va) for va in row[-1]]\n",
    "    print(row[0] + \" & \"+ \" & \".join(row_vals) + r\" \\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>new_index</th>\n",
       "      <th>Values</th>\n",
       "      <th>val_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDR MAE</td>\n",
       "      <td>scPhere-lvm</td>\n",
       "      <td>5.717934e-02</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDR MAE</td>\n",
       "      <td>scPhere-lvm + ELBO</td>\n",
       "      <td>3.185335e-01</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDR MAE</td>\n",
       "      <td>scPhere-lvm - constant overdispersion</td>\n",
       "      <td>2.996261e-02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDR MAE</td>\n",
       "      <td>scPhere-lvm - library size</td>\n",
       "      <td>1.672428e-01</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ranking score</td>\n",
       "      <td>scPhere-lvm</td>\n",
       "      <td>1.117339e-01</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ranking score</td>\n",
       "      <td>scPhere-lvm + ELBO</td>\n",
       "      <td>7.282319e-01</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ranking score</td>\n",
       "      <td>scPhere-lvm - constant overdispersion</td>\n",
       "      <td>2.687753e-01</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ranking score</td>\n",
       "      <td>scPhere-lvm - library size</td>\n",
       "      <td>3.044722e-01</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>khat</td>\n",
       "      <td>scPhere-lvm</td>\n",
       "      <td>8.979503e-02</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>khat</td>\n",
       "      <td>scPhere-lvm + ELBO</td>\n",
       "      <td>-1.041820e-01</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>khat</td>\n",
       "      <td>scPhere-lvm - constant overdispersion</td>\n",
       "      <td>1.307295e-01</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>khat</td>\n",
       "      <td>scPhere-lvm - library size</td>\n",
       "      <td>1.103871e-01</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NC</td>\n",
       "      <td>scPhere-lvm</td>\n",
       "      <td>6.223072e-02</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NC</td>\n",
       "      <td>scPhere-lvm + ELBO</td>\n",
       "      <td>3.730480e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NC</td>\n",
       "      <td>scPhere-lvm - constant overdispersion</td>\n",
       "      <td>2.110712e-01</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NC</td>\n",
       "      <td>scPhere-lvm - library size</td>\n",
       "      <td>1.054153e-01</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric                              new_index        Values  \\\n",
       "0         FDR MAE                            scPhere-lvm  5.717934e-02   \n",
       "1         FDR MAE                     scPhere-lvm + ELBO  3.185335e-01   \n",
       "2         FDR MAE  scPhere-lvm - constant overdispersion  2.996261e-02   \n",
       "3         FDR MAE             scPhere-lvm - library size  1.672428e-01   \n",
       "4   Ranking score                            scPhere-lvm  1.117339e-01   \n",
       "5   Ranking score                     scPhere-lvm + ELBO  7.282319e-01   \n",
       "6   Ranking score  scPhere-lvm - constant overdispersion  2.687753e-01   \n",
       "7   Ranking score             scPhere-lvm - library size  3.044722e-01   \n",
       "8            khat                            scPhere-lvm  8.979503e-02   \n",
       "9            khat                     scPhere-lvm + ELBO -1.041820e-01   \n",
       "10           khat  scPhere-lvm - constant overdispersion  1.307295e-01   \n",
       "11           khat             scPhere-lvm - library size  1.103871e-01   \n",
       "12             NC                            scPhere-lvm  6.223072e-02   \n",
       "13             NC                     scPhere-lvm + ELBO  3.730480e-07   \n",
       "14             NC  scPhere-lvm - constant overdispersion  2.110712e-01   \n",
       "15             NC             scPhere-lvm - library size  1.054153e-01   \n",
       "\n",
       "   val_text  \n",
       "0      0.06  \n",
       "1      0.32  \n",
       "2      0.03  \n",
       "3      0.17  \n",
       "4      0.11  \n",
       "5      0.73  \n",
       "6      0.27  \n",
       "7       0.3  \n",
       "8      0.09  \n",
       "9      -0.1  \n",
       "10     0.13  \n",
       "11     0.11  \n",
       "12     0.06  \n",
       "13      0.0  \n",
       "14     0.21  \n",
       "15     0.11  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_res1d = (\n",
    "    agg_res\n",
    "    .unstack()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"Metric\", \"algo_name\": \"Algorithm\", 0: \"Values\"})\n",
    "    .assign(val_text=lambda x: x.Values.round(2).astype(str))\n",
    ")\n",
    "agg_res1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# (\n",
    "#     res1d\n",
    "#     .groupby(\"algo_name\")\n",
    "#     .apply(lambda x: pearsonr(x.lfc_gt, x.lfc_estim2)[0])\n",
    "    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res1d.loc[lambda x: x.algo_name == \"scVI-lvm + layer norm\"].lfc_estim2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(res1d)\n",
    "    + p9.geom_point(p9.aes(x=\"lfc_gt\", y=\"lfc_estim2\"))\n",
    "    + p9.facet_wrap(\"algo_name\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
